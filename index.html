<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="keywords" content="Dataset reconstruction, Privacy">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Reconstructing Training Data from Trained Neural Networks</title>

	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-6W3Z069ZG5"></script>
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'G-6W3Z069ZG5');
	</script>
		
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<!-- Top. -->
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Reconstructing Training Data from Trained Neural Networks</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://nivha.github.io/">Niv Haim</a>*,
			</span>
            <span class="author-block">
              <a href="https://scholar.google.co.il/citations?user=LVk3xE4AAAAJ&hl=en">Gal Vardi</a>*,
			</span>
            <span class="author-block">
              <a href="https://scholar.google.co.il/citations?user=opVT1qkAAAAJ&hl=iw">Gilad Yehudai</a>*,
            </span>
            <span class="author-block">
              <a href="https://www.wisdom.weizmann.ac.il/~shamiro/">Ohad Shamir</a>,
            </span>
            <span class="author-block">
              <a href="http://www.weizmann.ac.il/math/irani/">Michal Irani</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Weizmann Institute of Science, Rehovot, Israel</span>
          </div>
		  <div class="is-size-6 publication-authors">
            <span class="author-block">* Equal contribution</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="./reconstruction_paper.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2206.07758"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark" disabled>
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (soon)</span>
                  </a>
              </span>
            </div>
						
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">

			<div class="container has-text-centered">
				<div class="content has-text-centered is-size-5">
					
					Reconstruction of training data from a trained binary classifier:

					<div class="content is-centered is-borderless" style="text-align: center">
						<video autoplay controls muted loop width=25%>
							<source src="./resources/2d_evolution.mp4" type="video/mp4">
						</video>
						
						<video autoplay controls muted loop width=25% style="image-rendering: pixelated;">
							<source src="./resources/cifar_evolution.mp4" type="video/mp4">
						</video>
						
						<video autoplay controls muted loop width=25%>
							<source src="./resources/mnist_evolution.mp4" type="video/mp4">
						</video>
					</div>
					Randomly initialized data points are "drifted" towards training samples by minimizing our proposed loss
					
										
				</div>				
			</div>
		
</section>



<!-- Abstract. -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
					<p>
					Understanding to what extent neural networks memorize training data is an intriguing question with practical and theoretical implications. 
					In this paper we show that in some cases a significant fraction of the training data can in fact be reconstructed from the parameters of a trained neural network classifier.
					We propose a novel reconstruction scheme that stems from recent theoretical results about the implicit bias in training neural networks with gradient-based methods.
					To the best of our knowledge, our results are the first to show that reconstructing a large portion of the actual training samples from a trained neural network classifier is generally possible.
					This has negative implications on privacy, as it can be used as an attack for revealing sensitive training data. 
					We demonstrate our method for binary MLP classifiers on a few standard computer vision datasets.
					</p>
		
        </div>
      </div>
    </div>
  </div>
</section>

		
		
<section class="section">
  <div class="container is-max-desktop">

    <!-- Applications. -->
    <div class="columns is-centered">
      <div class="column is-full-width">


			<h2 class="title is-3" id="analogies">Reconstructions</h2>
			<!-- <br/> -->
			<div class="columns is-justified">
				<div class="column">
					<p>
					We reconstruct training samples from binary classifiers.
					<br/>
					Below we show reconstructions from MLPs trained on 500 images of CIFAR10/MNIST, labeled as animals/vehicles and odd/even digit, respectively.
					<br/>
					(Train errors are zero and test accuracies are 88.0%/77.6%)
					</p>
				</div>
			</div>
			
			<img src="./resources/fig_3_cifar.png">
			<br/>
			<img src="./resources/fig_3_mnist.png">
			
			<br/>
			<br/>


      <h2 class="title is-3" id="analogies">Technical TL;DR</h2>
			<!-- <br/> -->
			<div class="columns is-justified">
				<div class="column">
					<p>
					Our approach relies on theoretical results about the implicit bias in training neural networks with gradient-based methods. The implicit bias has been studied extensively in recent years with the motivation of explaining generalization in deep learning.
					<br/>
					We use results by Liu &amp; Li (2019) and Ji &amp; Telgarsky (2020), which establish that, under some technical assumptions, if we train a neural network with the binary cross entropy loss, its parameters will converge to a stationary point of a certain margin-maximization problem. This result implies that the parameters of the trained network satisfy a set of equations w.r.t. the training dataset. In our approach, given a trained network, we find a dataset that solves this set of equations w.r.t. the trained parameters.
					</p>
					More specifically, the trained parameters &theta; and the dataset {(x<sub>i</sub>,y<sub>i</sub>)}<span class="supsub"><sup>n</sup><sub>i=1</sub></span> satisfy the following sets of equations (where &lambda;<sub>1</sub>,...,&lambda;<sub>n</sub> are real numbers and &Phi;(&theta;;&sdot;) represents the neural network with parameters &theta;):
				</div>
			</div>
			
			<div class="columns has-text-centered">
				<div class="column is-centered">
					<img src="./resources/kkt.svg">	
				</div>
			</div>

						
			<div class="columns is-justified">
				<div class="column is-centered">
					We use the stationary condition to conduct a novel loss function:
				</div>
			</div>	

			<div class="columns has-text-centered">
				<div class="column is-centered">
					<img src="./resources/loss.svg">	
				</div>
		  </div>

			<div class="columns is-justified">
				<div class="column is-centered">
					The animations at the top of this page show the trajectories of several x<sub>i</sub>, from a random noise intialization until they reach a datapoint from the training set, by minimizing the loss L.
				</div>
			</div>	


		</div>
	</div>
		

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{haim2022reconstructing,
  author    = {Haim, Niv and Vardi, Gal and Yehudai, Gilad and Shamir, Ohad and Irani, Michal},
  title     = {Reconstructing Training Data from Trained Neural Networks},
  journal   = {arXiv preprint arXiv:2206.07758},
  year      = {2022},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <!-- <a class="icon-link" -->
         <!-- href=""> -->
        <!-- <i class="fas fa-file-pdf"></i> -->
      <!-- </a> -->
      <a class="icon-link" href="https://github.com/giladude1/reconstruction" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8 has-text-centered">
        <div class="content">
          <p>
            This website is forked from the
			<a href="https://nerfies.github.io/">Nerfies website</a> and 						
			<a href="https://github.com/nerfies/nerfies.github.io">source code</a>
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
